# RAG Chatbot with FastAPI

A Retrieval Augmented Generation (RAG) chatbot that answers questions from PDF and TXT documents using LangChain and FastAPI.

## Features

- ğŸ“„ Loads and processes multiple PDF and TXT files
- ğŸ” Semantic search using vector embeddings (ChromaDB)
- ğŸ§  Powered by robust LangChain logic
- ğŸš€ Fast and scalable FastAPI backend
- ğŸ“š Automatic source document citation

## Project Structure

```
gen/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api.py           # FastAPI server application
â”‚   â””â”€â”€ core/            # Core logic
â”‚       â”œâ”€â”€ chatbot.py   # RAG chain and LLM interface
â”‚       â”œâ”€â”€ config.py    # Configuration settings
â”‚       â””â”€â”€ loader.py    # Document loading and processing
â”œâ”€â”€ documents/           # Place your PDF and TXT files here
â”œâ”€â”€ vector_store/        # Auto-generated vector store (do not upload to git)
â”œâ”€â”€ run_bot.bat          # Script to start the server
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # Environment variables (create this file)
â””â”€â”€ README.md            # This file
```

## Setup Instructions

### 1. Set Up Environment

This project uses a virtual environment.

#### Windows
```powershell
# Create and activate virtual environment
python -m venv venv
.\venv\Scripts\Activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Set Up Environment Variables

Create a `.env` file in the project root with your Groq API key:
```
GROQ_API_KEY=your_groq_api_key_here
```
Get a free key from [Groq Console](https://console.groq.com/).

### 3. Add Documents

Place your files in the `documents/` directory:
- `.pdf` files
- `.txt` files

### 4. Run the Application

Double-click `run_bot.bat` or run:
```bash
.\run_bot.bat
```

Or manually:
```bash
.\venv\Scripts\uvicorn app.api:app --reload
```

## Usage

Access the API documentation at:
**`http://localhost:8000/docs`**

1.  **Initialize**: Call `POST /initialize` to load your documents into the vector store.
2.  **Chat**: Call `POST /chat` with a JSON body `{"question": "Your question here"}`.
3.  **Health Check**: `GET /health` to verify system status.

## Configuration

Modify `app/core/config.py` to change:
- `CHUNK_SIZE`: Text chunk size (default: 1000)
- `GROQ_MODEL`: LLM model (default: "llama3-70b-8192")
- `EMBEDDING_MODEL`: Local embedding model

## Requirements

- Python 3.8+
- Groq API key (Free)

## License

MIT
